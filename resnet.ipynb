{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ay7h9jnfmify",
    "outputId": "1ce6ebeb-8ac5-4b7f-ec5b-21bda4b95643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "#import horovod.tensorflow as hvd\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYExwm633sYU"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# what is done:\n",
    "# partially done resnet model in tensorflow\n",
    "\n",
    "# what needs work:\n",
    "# 1. Create summaries - need to figure out what metrics are needed. \n",
    "# print out images from each block\n",
    "# testing accuracy vs step, training accuracy vs. step, loss vs step\n",
    "# ROC, AUC\n",
    "\n",
    "# 2. Input pipeline - lots of work! Best way is to .csv files of image directories and work with that\n",
    "\n",
    "# 3. Loss & Accuracy calculations need to be reviewed after bringing in new input pipeline\n",
    "\n",
    "# https://www.tensorflow.org/guide/datasets - figuring out how to import data\n",
    "# https://www.tensorflow.org/guide/summaries_and_tensorboard - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTAViKpJmkzv"
   },
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "y_train=y_train.reshape(y_train.shape[0])\n",
    "\n",
    "x_test=x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_train.shape[3])\n",
    "y_test=y_test.reshape(y_test.shape[0])\n",
    "\n",
    "num_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-RbVwKt1muSK",
    "outputId": "36aa7ca4-7833-4ab0-b2bb-777d6b773bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7Wxhyx9q_Fv"
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv2D(layer, \n",
    "           ft_size, \n",
    "           name, \n",
    "           ksize=1, \n",
    "           strides=[1, 1, 1, 1], \n",
    "           padding=\"SAME\", \n",
    "           initializer=tf.contrib.layers.xavier_initializer(),\n",
    "           dtype=tf.float32\n",
    "          ):\n",
    "  \n",
    "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):  \n",
    "    w = tf.get_variable(name='w', shape=[ksize, ksize, layer.shape[3], ft_size], dtype=dtype, initializer=initializer)\n",
    "    b = tf.get_variable(name='b', shape=[ft_size], dtype=dtype, initializer=tf.zeros_initializer())\n",
    "\n",
    "    layer = tf.nn.conv2d(input=layer, filter=w, strides=strides, padding=padding)\n",
    "    layer = tf.add(layer, b)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def respath_fn(respath, in_layer):\n",
    "    new_shape = [respath.get_shape().as_list()[0], np.amax([in_layer.get_shape().as_list()[1], respath.get_shape().as_list()[1]]), np.amax([in_layer.get_shape().as_list()[2], respath.get_shape().as_list()[2]]), np.amax([in_layer.get_shape().as_list()[3], respath.get_shape().as_list()[3]])]\n",
    "    \n",
    "    res_padding = [[0, 0], [0, new_shape[1]-respath.get_shape().as_list()[1]], [0, new_shape[2]-respath.get_shape().as_list()[2]], [0, new_shape[3]-respath.get_shape().as_list()[3]]]\n",
    "    in_padding = [[0, 0], [0, new_shape[1]-in_layer.get_shape().as_list()[1]], [0, new_shape[2]-in_layer.get_shape().as_list()[2]], [0, new_shape[3]-in_layer.get_shape().as_list()[3]]]\n",
    "    \n",
    "    a = tf.add(tf.pad(in_layer, in_padding, 'CONSTANT'), tf.pad(respath, res_padding, 'CONSTANT'))\n",
    "    \n",
    "    return a\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OK--ahgPm3x9",
    "outputId": "aefa8ac2-ddf4-4db0-c7b8-461db298656f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"output/add:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# graph\n",
    "\n",
    "HEIGHT = x_train.shape[1]\n",
    "WIDTH = x_train.shape[2]\n",
    "CHANNELS = x_train.shape[3]\n",
    "NUM_CLASS = num_class\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, WIDTH, HEIGHT, CHANNELS], name='x')\n",
    "y = tf.placeholder(dtype=tf.int64, shape=None, name='y')\n",
    "batch = tf.placeholder(dtype=tf.int64, shape=None, name='batch')\n",
    "\n",
    "with tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\n",
    "  layer = conv2D(layer=x, ft_size=64, name='_1', ksize=7, strides=[1, 2, 2, 1])\n",
    "\n",
    "resnet_layer = layer\n",
    "\n",
    "with tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\n",
    "  layer = tf.nn.max_pool(value=layer, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='max_pool')\n",
    "  for i in range(3):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 64, '_0')\n",
    "      layer = conv2D(layer, 64, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 256, '_2')\n",
    "\n",
    "resnet_layer = respath_fn(resnet_layer, layer)\n",
    "layer = resnet_layer\n",
    "\n",
    "with tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):      \n",
    "  for i in range(4):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 128, '_0')\n",
    "      layer = conv2D(layer, 128, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 512, '_2')\n",
    "\n",
    "resnet_layer = respath_fn(resnet_layer, layer)\n",
    "layer = resnet_layer\n",
    "    \n",
    "with tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE): \n",
    "  for i in range(6):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 256, '_0')\n",
    "      layer = conv2D(layer, 256, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 1024, '_2')\n",
    "\n",
    "resnet_layer = respath_fn(resnet_layer, layer)\n",
    "layer = resnet_layer\n",
    "\n",
    "with tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE): \n",
    "  for i in range(3):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 512, '_0')\n",
    "      layer = conv2D(layer, 512, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 2048, '_2')\n",
    "\n",
    "with tf.variable_scope(\"output\", reuse=tf.AUTO_REUSE):      \n",
    "  layer = tf.nn.avg_pool(value=layer, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME', name='avg_pool')\n",
    "#   layer = tf.contrib.layers.fully_connected(layer, 1000)\n",
    "  layer = tf.contrib.layers.flatten(layer)\n",
    "  w_loss = tf.get_variable(name='w', shape=[layer.shape[1], NUM_CLASS], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "  b_loss = tf.get_variable(name='b', shape=[NUM_CLASS], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "  layer = tf.matmul(layer, w_loss) + b_loss\n",
    "\n",
    "with tf.variable_scope(\"loss\", reuse=tf.AUTO_REUSE):\n",
    "  global_step = tf.train.get_or_create_global_step()\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y, 10), logits=layer))\n",
    "  optimize = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss, global_step=global_step)\n",
    " # optimize = hvd.DistributedOptimizer(optimize)\n",
    "\n",
    "with tf.variable_scope(\"accuracy\", reuse=tf.AUTO_REUSE):     \n",
    "  softmax = tf.argmax(tf.nn.softmax(logits=layer, axis=1), axis=1)\n",
    "  accuracy = tf.reduce_mean(tf.cast(tf.equal(softmax, y), tf.float32))*100\n",
    "\n",
    "saver = tf.train.Saver()  \n",
    "    \n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96cmRo-ynl0b",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-1c82f2914413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcurrent_global_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leftbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leftbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leftbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leftbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leftbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leftbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "config = tf.ConfigProto()\n",
    "# config.intra_op_parallelism_threads =68\n",
    "# config.inter_op_parallelism_threads =4\n",
    "# tf.session(config=config)\n",
    "# this code supposedly needs to be on nersc\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(30):\n",
    "        current_global_step, current_loss, current_accuracy, _ = sess.run([global_step, loss, accuracy, optimize], feed_dict={x: x_train[0:50], y: y_train[0:50]})\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            current_accuracy = sess.run([accuracy], feed_dict={x: x_test[0:10], y: y_test[0:10]})\n",
    "            print('loss: ', current_loss)\n",
    "            print('accuracy: %.2f%%' % current_accuracy[0])\n",
    "\n",
    "    current_accuracy = sess.run([accuracy], feed_dict={x: x_train[0:50], y: y_train[0:50]})\n",
    "    print('accuracy: %.2f%%' % current_accuracy[0])            \n",
    "\n",
    "    summary_writer = tf.summary.FileWriter('./tmp', graph=sess.graph)\n",
    "    summary_op = tf.summary.merge_all() \n",
    "    \n",
    "    saver.save(sess, save_path='./tmp/model.chkpt', global_step=current_global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8AeHQ953RWQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-851075204988>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-851075204988>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    a = np.zeros([32:d.shape[0], np.amax([d.shape[1], z.shape[1]]), np.amax([d.shape[2], z.shape[2]]), np.amax([d.shape[3], z.shape[3]])])\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "d = np.ones([16, 32, 32, 64])\n",
    "z = np.ones([16, 28, 28, 128])\n",
    "\n",
    "np.amax([d.shape[1], z.shape[1]])\n",
    "\n",
    "a = np.zeros([d.shape[0], np.amax([d.shape[1], z.shape[1]]), np.amax([d.shape[2], z.shape[2]]), np.amax([d.shape[3], z.shape[3]])])\n",
    "b = np.zeros(a.shape)\n",
    "print(b.shape)\n",
    "\n",
    "a[:d.shape[0], :d.shape[1], :d.shape[2], :d.shape[3]] = d\n",
    "b[:z.shape[0], :z.shape[1], :z.shape[2], :z.shape[3]] = z\n",
    "\n",
    "ret = np.add(a, b).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
