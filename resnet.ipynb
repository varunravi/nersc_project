{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ay7h9jnfmify",
    "outputId": "1ce6ebeb-8ac5-4b7f-ec5b-21bda4b95643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "#import horovod.tensorflow as hvd\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYExwm633sYU"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# what is done:\n",
    "# partially done resnet model in tensorflow\n",
    "\n",
    "# what needs work:\n",
    "# 1. Create summaries - need to figure out what metrics are needed. \n",
    "# print out images from each block\n",
    "# testing accuracy vs step, training accuracy vs. step, loss vs step\n",
    "# ROC, AUC\n",
    "\n",
    "# 2. Input pipeline - lots of work! Best way is to .csv files of image directories and work with that\n",
    "\n",
    "# 3. Loss & Accuracy calculations need to be reviewed after bringing in new input pipeline\n",
    "\n",
    "# https://www.tensorflow.org/guide/datasets - figuring out how to import data\n",
    "# https://www.tensorflow.org/guide/summaries_and_tensorboard - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTAViKpJmkzv"
   },
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "y_train=y_train.reshape(y_train.shape[0])\n",
    "\n",
    "x_test=x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_train.shape[3])\n",
    "y_test=y_test.reshape(y_test.shape[0])\n",
    "\n",
    "num_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-RbVwKt1muSK",
    "outputId": "36aa7ca4-7833-4ab0-b2bb-777d6b773bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7Wxhyx9q_Fv"
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv2D(layer, \n",
    "           ft_size, \n",
    "           name, \n",
    "           ksize=1, \n",
    "           strides=[1, 1, 1, 1], \n",
    "           padding=\"SAME\", \n",
    "           initializer=tf.contrib.layers.xavier_initializer(),\n",
    "           dtype=tf.float32\n",
    "          ):\n",
    "  \n",
    "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):  \n",
    "    w = tf.get_variable(name='w', shape=[ksize, ksize, layer.shape[3], ft_size], dtype=dtype, initializer=initializer)\n",
    "    b = tf.get_variable(name='b', shape=[ft_size], dtype=dtype, initializer=tf.zeros_initializer())\n",
    "\n",
    "    layer = tf.nn.conv2d(input=layer, filter=w, strides=strides, padding=padding)\n",
    "    layer = tf.add(layer, b)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def respath_fn(respath, in_layer, name):\n",
    "\n",
    "    with tf.variable_scope(\"residual_path\"+name, reuse=tf.AUTO_REUSE):      \n",
    "\n",
    "        new_shape = [respath.get_shape().as_list()[0], np.amax([in_layer.get_shape().as_list()[1], respath.get_shape().as_list()[1]]), np.amax([in_layer.get_shape().as_list()[2], respath.get_shape().as_list()[2]]), np.amax([in_layer.get_shape().as_list()[3], respath.get_shape().as_list()[3]])]\n",
    "\n",
    "        res_padding = [[0, 0], [0, new_shape[1]-respath.get_shape().as_list()[1]], [0, new_shape[2]-respath.get_shape().as_list()[2]], [0, new_shape[3]-respath.get_shape().as_list()[3]]]\n",
    "        in_padding = [[0, 0], [0, new_shape[1]-in_layer.get_shape().as_list()[1]], [0, new_shape[2]-in_layer.get_shape().as_list()[2]], [0, new_shape[3]-in_layer.get_shape().as_list()[3]]]\n",
    "\n",
    "        a = tf.add(tf.pad(in_layer, in_padding, 'CONSTANT'), tf.pad(respath, res_padding, 'CONSTANT'))\n",
    "\n",
    "        return a\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OK--ahgPm3x9",
    "outputId": "aefa8ac2-ddf4-4db0-c7b8-461db298656f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"output/add:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# graph\n",
    "HEIGHT = x_train.shape[1]\n",
    "WIDTH = x_train.shape[2]\n",
    "CHANNELS = x_train.shape[3]\n",
    "NUM_CLASS = num_class\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, WIDTH, HEIGHT, CHANNELS], name='x')\n",
    "y = tf.placeholder(dtype=tf.int64, shape=None, name='y')\n",
    "batch = tf.placeholder(dtype=tf.int64, shape=None, name='batch')\n",
    "\n",
    "with tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\n",
    "  layer = conv2D(layer=x, ft_size=64, name='_1', ksize=7, strides=[1, 2, 2, 1])\n",
    "\n",
    "resnet_layer = layer\n",
    "\n",
    "with tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\n",
    "  layer = tf.nn.max_pool(value=layer, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='max_pool')\n",
    "  for i in range(3):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 64, '_0')\n",
    "      layer = conv2D(layer, 64, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 256, '_2')\n",
    "\n",
    "resnet_layer = respath_fn(resnet_layer, layer, '_0')\n",
    "layer = resnet_layer\n",
    "\n",
    "with tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):      \n",
    "  for i in range(4):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 128, '_0')\n",
    "      layer = conv2D(layer, 128, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 512, '_2')\n",
    "\n",
    "resnet_layer = respath_fn(resnet_layer, layer, '_1')\n",
    "layer = resnet_layer\n",
    "    \n",
    "with tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE): \n",
    "  for i in range(6):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 256, '_0')\n",
    "      layer = conv2D(layer, 256, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 1024, '_2')\n",
    "\n",
    "resnet_layer = respath_fn(resnet_layer, layer, '_2')\n",
    "layer = resnet_layer\n",
    "\n",
    "with tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE): \n",
    "  for i in range(3):\n",
    "    with tf.variable_scope(\"block_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "      layer = conv2D(layer, 512, '_0')\n",
    "      layer = conv2D(layer, 512, '_1', ksize=3)\n",
    "      layer = conv2D(layer, 2048, '_2')\n",
    "\n",
    "with tf.variable_scope(\"output\", reuse=tf.AUTO_REUSE):      \n",
    "  layer = tf.nn.avg_pool(value=layer, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME', name='avg_pool')\n",
    "#   layer = tf.contrib.layers.fully_connected(layer, 1000)\n",
    "  layer = tf.contrib.layers.flatten(layer)\n",
    "  w_loss = tf.get_variable(name='w', shape=[layer.shape[1], NUM_CLASS], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "  b_loss = tf.get_variable(name='b', shape=[NUM_CLASS], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "  layer = tf.matmul(layer, w_loss) + b_loss\n",
    "\n",
    "with tf.variable_scope(\"loss\", reuse=tf.AUTO_REUSE):\n",
    "  global_step = tf.train.get_or_create_global_step()\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y, 10), logits=layer))\n",
    "  optimize = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss, global_step=global_step)\n",
    " # optimize = hvd.DistributedOptimizer(optimize)\n",
    "\n",
    "with tf.variable_scope(\"accuracy\", reuse=tf.AUTO_REUSE):     \n",
    "  softmax = tf.argmax(tf.nn.softmax(logits=layer, axis=1), axis=1)\n",
    "  accuracy = tf.reduce_mean(tf.cast(tf.equal(softmax, y), tf.float32))*100\n",
    "\n",
    "saver = tf.train.Saver()  \n",
    "    \n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96cmRo-ynl0b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  13.12176\n",
      "accuracy: 10.00%\n",
      "loss:  23.002483\n",
      "accuracy: 30.00%\n",
      "loss:  9.220811\n",
      "accuracy: 0.00%\n",
      "loss:  5.274068\n",
      "accuracy: 50.00%\n",
      "loss:  2.4148264\n",
      "accuracy: 0.00%\n",
      "loss:  1.0870337\n",
      "accuracy: 10.00%\n",
      "accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = tf.ConfigProto()\n",
    "# config.intra_op_parallelism_threads =68\n",
    "# config.inter_op_parallelism_threads =4\n",
    "# tf.session(config=config)\n",
    "# this code supposedly needs to be on nersc\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(30):\n",
    "        current_global_step, current_loss, current_accuracy, _ = sess.run([global_step, loss, accuracy, optimize], feed_dict={x: x_train[0:50], y: y_train[0:50]})\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            current_accuracy = sess.run([accuracy], feed_dict={x: x_test[0:10], y: y_test[0:10]})\n",
    "            print('loss: ', current_loss)\n",
    "            print('accuracy: %.2f%%' % current_accuracy[0])\n",
    "\n",
    "    current_accuracy = sess.run([accuracy], feed_dict={x: x_train[0:50], y: y_train[0:50]})\n",
    "    print('accuracy: %.2f%%' % current_accuracy[0])            \n",
    "\n",
    "    summary_writer = tf.summary.FileWriter('./tmp', graph=sess.graph)\n",
    "    summary_op = tf.summary.merge_all() \n",
    "    \n",
    "    saver.save(sess, save_path='./tmp/model.chkpt', global_step=current_global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8AeHQ953RWQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-851075204988>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-851075204988>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    a = np.zeros([32:d.shape[0], np.amax([d.shape[1], z.shape[1]]), np.amax([d.shape[2], z.shape[2]]), np.amax([d.shape[3], z.shape[3]])])\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "d = np.ones([16, 32, 32, 64])\n",
    "z = np.ones([16, 28, 28, 128])\n",
    "\n",
    "np.amax([d.shape[1], z.shape[1]])\n",
    "\n",
    "a = np.zeros([d.shape[0], np.amax([d.shape[1], z.shape[1]]), np.amax([d.shape[2], z.shape[2]]), np.amax([d.shape[3], z.shape[3]])])\n",
    "b = np.zeros(a.shape)\n",
    "print(b.shape)\n",
    "\n",
    "a[:d.shape[0], :d.shape[1], :d.shape[2], :d.shape[3]] = d\n",
    "b[:z.shape[0], :z.shape[1], :z.shape[2], :z.shape[3]] = z\n",
    "\n",
    "ret = np.add(a, b).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
